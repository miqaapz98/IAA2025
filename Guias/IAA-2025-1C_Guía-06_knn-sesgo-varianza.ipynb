{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "810eb94f-8f75-4d0e-95da-ead58e3d6563",
   "metadata": {},
   "source": [
    "# Vecinos más cercanos (K-NN) y Balance Sesgo - Varianza\n",
    "\n",
    "Proponemos explorar el balance entre sesgo y varianza construyendo modelos de diferente complejidad empleando la aproximación por vecinos más cercanos. Asimismo, exploraremos este balance en ejercicios complementarios basados en árboles de decisión para distintas profundidades. Primero, analizaremos el balance en modelos de regresión y luego con clasificadores.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7252b3df-91e6-4a3d-83dd-7acb12b83022",
   "metadata": {},
   "source": [
    "## Regresión por vecinos más cercanos\n",
    "\n",
    "### Atributos numéricos\n",
    "\n",
    "Vamos a definir y ajustar un modelo de regresión por vecinos más cercanos para la variable `body_mass_g` del conjunto de datos de pingüinos. En primer lugar, solamente consideraremos los atributos numéricos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492da4c8-4bfc-4094-9698-a4bc058f7d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permite identificar donde estamos parados para \n",
    "# luego escribir el PATH correcto para acceder al conjunto de datos\n",
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e0b860-1864-4b21-bbfa-27a1c5a5ada7",
   "metadata": {},
   "source": [
    "Al igual que en las guías anteriores, vamos a leer el conjunto de datos de pingüinos `penguins_size.csv`. Recordamos que contiene algunos `NA` que debemos eliminar... Y, además, hay una muestra con el atributo `sex` definido como \".\" que también borraremos..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0c4239-fa88-4202-928d-4ec3cb2df972",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pgs = pd.read_csv('path_to/penguins_size.csv')\n",
    "# COMPLETAR\n",
    "# Remover NA y .\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9b196f-3221-4ef9-be76-05be4d8391c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirmamos la distribución de muestras por especie\n",
    "# Presenta un balance aceptable?\n",
    "pgs['species'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9a0b3e-fd24-4e11-84d9-80a960bb1014",
   "metadata": {},
   "source": [
    "Ahora, nos quedamos solamente con los atributos numéricos y separamos en datos de entrenamiento y prueba. Recordamos que nuestro *target* será `body_mass_g`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49e35687-6822-40d8-8c32-f00d970599b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# COMPLETAR\n",
    "# X = \n",
    "# y = \n",
    "# X_train, X_test, y_train, y_test = \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bec05f7-418f-4444-a654-579286f76cae",
   "metadata": {},
   "source": [
    "Vamos a generar una instancia de la clase `KNeighborsRegressor()` que nos permitirá realizar un ajuste por vecinos más cercanos. Asimismo, es fundamental reescalar los atributos para que las *distancias* en las diferentes direcciones sean comparables incorporando previamente una transformación de la clase `StandardScaler()`. Dado que siempre ambos procesos irán encadenados, es conveniente introducir un `Pipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6655a81f-1d37-417a-bf49-aa0144fc518f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# COMPLETAR\n",
    "# Definir un Pipeline que encade un StandardScaler y un KNeighborsRegressor\n",
    "# \n",
    "# pipe = \n",
    " \n",
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abefff9-3239-4ee3-8a28-10d124ead34d",
   "metadata": {},
   "source": [
    "Ahora, podemos operar con el *pipe* como si se tratara de un estimador regular. Es decir, podemos aplicar al *pipe* los métodos `.fit()`, `.predict()`, o cualquier otro, en el orden correspondiente. Particularmente, nos interesa estudiar el balance sesgo-varianza. En este caso, podemos definir un ciclo que itere sobre el número de primeros vecinos y almacenar los resultados de algunas métricas tanto en entrenamiento como en prueba. Por ejemplo, podemos tomar el método `.score()` que recupera el valor del coeficiente de determinación ($R^2$).\n",
    "\n",
    "Para cada iteración, debemos modifcar el número de vecinos más cercanos. Como vimos, podemos acceder a esta configuración a través del método `.set_params()` y pasando como argumento `knn__n_neighbors=k`. En este caso, `k` representa el número de vecinos más cercanos y la variable o *key* se construye como \"nombre_del_paso + doble guión bajo (__) + nombre del parámetro\".  En este ejemplo elegimos como nombre del segundo paso del `Pipeline` `knn`.\n",
    "\n",
    "Sugerimos para `k` valores en el rango entre 1 y 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15fbeb6b-6751-467a-a0a8-6c9f3a505116",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "k_all = np.arange(2,41, 2)\n",
    "r2_train = np.array([])\n",
    "r2_test = np.array([])\n",
    "# rmse_train \n",
    "# rmse_test\n",
    "for k in k_all:\n",
    "    pipe.set_params(knn__n_neighbors=k)\n",
    "    pipe.fit(X_train, y_train)\n",
    "    r2_train = np.append(r2_train, [pipe.score(X_train, y_train)])\n",
    "    r2_test = np.append(r2_test, [pipe.score(X_test, y_test)])\n",
    "    # rmse_train = \n",
    "    # rmse_test = \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5419cbf0-5dc9-43d9-bcf8-82fde62daf1e",
   "metadata": {},
   "source": [
    "En este ejemplo, contamos con los $R^2$ de entrenamiento y prueba en función del número de vecinos. Así, podemos trazar ambas curvas que usualmente se representan en función de 1/k. \n",
    "\n",
    "**Ejercicio**: almacenar simultaneamente los RMSE de entrenamiento y prueba en función del número de vecinos. Realizar el gráfcio correspondiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abef1aa-2de3-4c2a-8848-1ce0b9b0dd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(nrows = 1,ncols = 2, dpi=100)\n",
    "ax[0].plot(1/k_all, rmse_train, label='Train', linestyle='-.')\n",
    "ax[0].plot(1/k_all, rmse_test, label='Test', linestyle='-')\n",
    "ax[0].set_xlim([0,np.max(1/k_all)])\n",
    "ax[0].set_xlabel(\"1/k\")\n",
    "ax[0].set_ylabel(\"RMSE (gr)\")\n",
    "ax[0].legend(loc='lower left')\n",
    "\n",
    "ax[1].plot(1/k_all, r2_train, label='Train', linestyle='-.')\n",
    "ax[1].plot(1/k_all, r2_test, label='Test', linestyle='-')\n",
    "ax[1].set_xlim([0,np.max(1/k_all)])\n",
    "ax[1].set_xlabel(\"1/k\")\n",
    "ax[1].set_ylabel(\"R2\")\n",
    "ax[1].legend(loc='lower left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5034aaca-a200-40d9-9391-a5908771d56e",
   "metadata": {},
   "source": [
    "**Ejericio**: Señalar en las figuras anteriores las zonas de sobreajuste (over-fitting) y subajuste (under-fitting). Explicar cómo se las encuentra. ¿Cuál podría ser un rango de `k` óptimo? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a3c38d-f116-4bf6-a78b-db5ab66496cb",
   "metadata": {},
   "source": [
    "### Atributos numéricos y categóricos\n",
    "\n",
    "Proponemos repetir el estudio del balance sesgo-varianza pero ahora también incluyendo las variables categóricas `species` y `sex` en el análisis. Separamos en datos de entrenamiento y prueba recordando que nuestro *target* será `body_mass_g`. Asimismo, construimos listas con los nombres de los atriutos numéricos y categóricos que serán usadas más adelante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf034ff-52f8-4d53-a8a5-a126e2489ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "pgs_numeric = pgs.select_dtypes(include='number').columns.to_list()\n",
    "pgs_numeric.remove('body_mass_g')\n",
    "pgs_cat = ['species', 'sex']\n",
    "pgs_drop = ['island']\n",
    "print(pgs_numeric)\n",
    "\n",
    "# COMPLETAR\n",
    "# X = \n",
    "# y = \n",
    "# X_train, X_test, y_train, y_test = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661afe35-f2f7-451c-932d-e66b59473b17",
   "metadata": {},
   "source": [
    "Notamos que las variables numéricas y categóricas no pueden tratarse de la misma manera. Por un lado, continuaremos reescalando los datos cuantitativos usando la clase `StandardScaler()`. Por otro lado, codificaremos los datos cualitativos aplicando una transformación por `OneHotEncoder()`. Ambas operaciones se pueden incluir en un mismo preprcesamiento con la ayuda de `ColumnTransformer`. Finalmente, este preprocesamiento se encadena con la regresión por vecinos más cercanos mediante `Pipeline`. El objetivo es que los datos sean transformados, según su tipo, antes de llegar al regresor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61261cc-0207-4ab2-9a2d-b8c65487a3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "preproc = ColumnTransformer(\n",
    "    [('scaler', StandardScaler(), pgs_numeric),\n",
    "     ('one-hot',OneHotEncoder(), pgs_cat),\n",
    "     ('drop', 'drop', pgs_drop),\n",
    "    ])\n",
    "\n",
    "pipe = Pipeline([('preproc', preproc), ('knn', KNeighborsRegressor())]) \n",
    "pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f6a76a-c6e4-4c41-bc65-197d2597951d",
   "metadata": {},
   "source": [
    "De manera análoga, buscamos realizar gráficos para las distintas métricas consideradas, tanto con datos de entrenamiento como de prueba. Para ello, nos planteamos un ciclo que itera sobre un número creciente de primeros vecinos (en el rango entre 1 y 50). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e42f48b-3289-41f5-9bea-439928276795",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "# COMPLETAR\n",
    "# Realizar un ciclo sobre el número de vecinos K, almacenar las respectivas métricas\n",
    "# k_all = \n",
    "# rmse_train = \n",
    "# rmse_test = \n",
    "# for k in k_all:\n",
    "    # Configurar el número de vecinos en k\n",
    "\n",
    "    # Ajustar y calcular las métricas para entrenamiento y prueba\n",
    "\n",
    "    # Alamcenar K, rmse_train y rmse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e695637-a77c-428d-98dc-120f24e503be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPLETAR\n",
    "# Elaborar una figura que trace los RMSE de prueba y entrenamiento en función de 1/k\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12142c98-4091-45a1-afe0-7a83ac691721",
   "metadata": {},
   "source": [
    "**Ejercicio**: Identificar regiones de sobre y subajuste. ¿Se podría afirmar que el modelo que toma variables numéricas y categóricas tiene un mejor desempeño que el que solo emplea datos numéricos? Repetir el análisis usando `DecisionTreeRegressor` en función de diferentes profundidades."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209d4cdb-c9c7-4c3f-9024-b22d8a29cd38",
   "metadata": {},
   "source": [
    "## Clasificación por vecinos más cercanos\n",
    "\n",
    "Vamos a definir y ajustar un modelo de clasificación por vecinos más cercanos para la variable `species` del conjunto de datos de pingüinos. En este caso consideraremos solamente el atributos numérico `flipper_length_mm` y, adicionalmente, la variable categórica `sex`. Deberemos:\n",
    "\n",
    "1. Separa en datos de entrenamiento y prueba.\n",
    "2. Elaborar una transformación por columnas que aplique la clase `StandardScaler` a los datos numéricos y la clase `OneHotEncoder` a los cateóricos.\n",
    "3. Elaborar un pipeline que encadene el preprocesado por columnas y, luego, inicie el proceso de `KNeighborsClassifier()`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ccab52-9c8a-4636-839e-a8e8479285a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pgs_numeric = ['flipper_length_mm']\n",
    "pgs_cat = ['sex']\n",
    "\n",
    "print(pgs_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e106be7-6b81-4a02-b156-c83c0e02a607",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# COMPLETAR\n",
    "# X = \n",
    "# y = \n",
    "# X_train, X_test, y_train, y_test = \n",
    "\n",
    "# Definir un preprocesado pór columnas que aplique \n",
    "# StandardScaler() en la variable numérica\n",
    "# OneHotEncoder() en la variable categórica\n",
    "\n",
    "# preproc = ColumnTransformer(\n",
    "#\n",
    "#\n",
    "#    )\n",
    "\n",
    "# Definir un Pipeline que encadene el\n",
    "# preprocesado y el clasificador de primeros vecinos\n",
    "\n",
    "# pipe = \n",
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834e4db6-284a-4c38-b3a0-216b1805102f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93c3dc8-2521-4a84-a2c2-637b04f92930",
   "metadata": {},
   "source": [
    "El análisis del balance sesgo-varianza para los clasificadores conduce, al igual que antes, a la puesta en práctica de un ciclo que recorre valores crecientes de `k` para vecinos más cercanos y, calcula y almacena la exactitud (`accuracy_score`). Dado que las tres especies de pingüinos se presentan en cantidades iguales, la exactitud es una métrica adecuada para evaluar el desempeño general de los clasificadores. Debemos recordar que otras métricas, como el recall o precision deberían calcularse por especie ya que operamos con tres clases diferentes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26059ea2-1bcd-4e8e-8c9c-bb50e6919577",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# COMPLETAR\n",
    "# Realizar un ciclo sobre el número de vecinos K, almacenar la respectiva métrica\n",
    "# k_all = \n",
    "# acc_train =\n",
    "# acc_test = \n",
    "for k in range(1,30):\n",
    "    # Configurar el número de vecinos en k\n",
    "\n",
    "    # Ajustar y calcular la métrica para entrenamiento y prueba\n",
    "\n",
    "    # Alamcenar K, acc_train y acc_test\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0894f12-468a-45e3-abf9-eb3ae03aeceb",
   "metadata": {},
   "source": [
    "Los valores registrados de exactitud en función del número de primeros vecinos, tanto para los conjuntos de pureba como entrenamiento nos habilitan el trazado de una figura que representa el balance sesgo-varianza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753c1454-715a-4f6c-8538-b70c405fc11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPLETAR\n",
    "# Elaborar una figura que trace los Accuracy de prueba y entrenamiento en función de 1/k\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36df6f4a-b9e0-4126-81f8-ed7a22260fb2",
   "metadata": {},
   "source": [
    "**Pregunta**: Sabiendo que el atributo `sex` es binario, ¿podríamos pasar como argumento de `OneHotEncoder` la opción `drop='first'`? ¿Tiene impacto en el resultado?\n",
    "\n",
    "**Ejercicio**: Reconocer zonas de sobre y subajuste. Elegir un `k`, número de primeros vecinos, que considere ofrezca el mejor balance sesgo-varianza. Volver a ajustar el modelo para dicho `k` e imprimir las predicciones para el conjunto de prueba. Notar que la predicción es el nombre de la especie correspondiente a cada muestra o dato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aee5542-267a-4aa3-85ed-e9e1ba58b7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPLETAR\n",
    "# elegir el K que considere alcanza el mejor balance entre sesgo y varianza\n",
    "# k =\n",
    "\n",
    "# pipe.set_params(knn__n_neighbors=k)\n",
    "# Ajustar el modelo en el nuevo k con datos de entrenamiento\n",
    "\n",
    "# Realizar la predicción correspondiente para datos de prueba\n",
    "# y_pred_test = \n",
    "print(y_pred_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8e1d26-33d3-4d93-a570-18c30d0ea9ed",
   "metadata": {},
   "source": [
    "**Ejercicio**: Calcular la matriz de confusión para `k` cuando toma el valor que se considera realiza el mejor balance entre sesgo y varianza. Identificar que especies confunde el clasificador en mayor cantidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d467c439-15a3-4e50-ac69-98b09d9ffe05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "# COMPLETAR\n",
    "# Imprimir la matriz de confusión para los datos de prueba con el k óptimo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54f0da4-238b-4e7a-855f-34f766612c3a",
   "metadata": {},
   "source": [
    "**Ejercicio**: Representar en una figura las especies que serían predecidas cuando `flipper_length_mm`varía en el rango entre 160 y 240, para ambos sexos. Superponer con lospuntos de entrenamiento. Observar como cambia la figura con la elección del número de vecinos más cercanos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c1bd05-0e38-4e59-a5d8-9467c0522fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPLETAR \n",
    "# Realizar la representación de especies en función de\n",
    "# los atributos flipper_length_mm y sex\n",
    "\n",
    "# Armar un DataFrame que recorra los valores \n",
    "# de flipper_length_mm desde el mínimo hasta el máximo\n",
    "# y el atributo sex en sus valores Male y FEMALE\n",
    "\n",
    "# Predecir las especies \n",
    "\n",
    "# Considerar los métodos de seaborn \n",
    "# catplot, stripplot o scatterplot para la representación \n",
    "# de las especies en función del atributo \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee938e7-0ecf-4764-98f9-b33abc2aed8b",
   "metadata": {},
   "source": [
    "**Ejercicio**: Explorar cómo afecta la clasificación si los *targets* se pesan por la inversa de la distancia al punto.\n",
    "\n",
    "**Ejercicio**: Repetir el análisis usando `DecisionTreeClassifier` en función de diferentes profundidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464752b3-8cf8-4460-884b-d25bf4c87469",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
