{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrWGjTVzUevQ"
      },
      "source": [
        "# Introducción al Aprendizaje Automático\n",
        "\n",
        "## 1. Clasificación Binaria - Regresor Logístico\n",
        "\n",
        "Dentro del amplio mundo del Aprendizaje Automático, los modelos de clasificación se presentan como herramientas para categorizar y etiquetar datos en distintos grupos o clases. Estos modelos abarcan una variedad de técnicas, adaptándose a los diferentes tipos de datos y problemáticas. Previamente, exploramos los Árboles de Decisión, un modelo que segmenta el espacio de características en decisiones jerárquicas. Sin embargo, en esta ocasión, centraremos nuestra atención en el Regresor Logístico, un modelo matemático que, a pesar de su nombre, es ampliamente utilizado para tareas de clasificación binaria y multiclase, aprovechando la relación entre variables independientes y la probabilidad de ocurrencia de un evento particular.\n",
        "\n",
        "#### Conjunto de datos\n",
        "\n",
        "Para mostrar de forma clara los conceptos, utilizaremos el mismo dataset artificial utilizado en la clase 2:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ogJlLb4OfV3Q"
      },
      "outputs": [],
      "source": [
        "#Librerias que vamos a utilizar en este notebook\n",
        "import numpy as npnp\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RddXDVxCfV3S"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('IAA_Guia_2_clasificacion_binaria.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DtjMy5eYfV3T"
      },
      "outputs": [],
      "source": [
        "# Plot the data\n",
        "plt.scatter(df.x1, df.x2, c=df.target, cmap='bwr')\n",
        "plt.xlabel('Atributo 1 - x1')\n",
        "plt.ylabel('Atributo 2 - x2')\n",
        "\n",
        "### Create legend with red and blue colors, and text \"clase 1\" and \"clase 2\"\n",
        "red_patch = plt.plot([],[], marker=\"o\", ms=10, ls=\"\", mec=None, color='r', label='clase 1')\n",
        "blue_patch = plt.plot([],[], marker=\"o\", ms=10, ls=\"\", mec=None, color='b', label='clase 0')\n",
        "plt.legend(handles=[red_patch[0], blue_patch[0]], loc='upper right', fontsize=12)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkG_-_xJfV3U"
      },
      "source": [
        "Los modelos lineales de clasificación consisten en trazar una línea recta que divida de un lado una clase y de otro lado otra. En el caso de más de dos dimensiones, consiste en colocar un hiperplano que divida el espacio en dos mitades; a un lado y el otro del hiperplano, clasificamos como una u otra clase.\n",
        "\n",
        "La manera matemática de caracterizar una linea recta en un plano es con una simple ecuación:\n",
        "$$ \\beta_1  x_1 + \\beta_2 x_2 = cte $$\n",
        "donde $\\beta_1$ y $\\beta_2$ determinan el ángulo de la linea, y la constante mueve paralelamente esa recta. A los números $\\beta_i$ se le llaman _pesos_.\n",
        "\n",
        "En el caso más general de $n$ dimensiones, generaliza de igual forma:\n",
        "$$\n",
        "\\beta_0 + \\beta_1  x_1 + \\beta_2 x_2 + ... + \\beta_n  x_n = 0\n",
        "$$\n",
        "donde a la constante la reescribimo como $-\\beta_0$ para llevar la ecuación a una forma convencional.\n",
        "\n",
        "- Al hiperplano que separa los puntos se le llama **_\"frontera de decisión\"_**.\n",
        "\n",
        "- Éste esta caracterizado por ser donde se anula la función lineal $f(\\vec \\beta, \\vec x) = \\beta_0 + \\beta_1  x_1 + \\beta_2 x_2 + ... + \\beta_n  x_n $\n",
        "\n",
        "- A la función usada para clasificar se le llama **función discriminante**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkCp5RARfV3W"
      },
      "source": [
        "**Ejercicio:** Para el caso con dos atributos, responde:\n",
        "* ¿Cómo deberían ser $\\beta_1$ y $\\beta_2$ para que la recta sea horizontal?¿Y para que sea vertical?\n",
        "* ¿Cómo se relacionan $x_1$, $x_2$, $\\beta_0$, $\\beta_1$ y $\\beta_2$ con la pendiente de la recta y la ordenada al origen de la forma lineal $y = mx + b$?\n",
        "\n",
        "**Ejercicio:** Explorá la función `model` y utilizala - junto con `plot` - para encontrar la mejor frontera de decisión."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IadISNokfV3X"
      },
      "outputs": [],
      "source": [
        "def model(beta, x1, x2):\n",
        "    return beta[0] +beta[1]*x1 + beta[2]*x2 > 0\n",
        "\n",
        "def plot(x1, x2, target, pred, beta=[]):\n",
        "\n",
        "    plt.scatter(x1[target==0], x2[target==0], marker='o', c=np.where(pred[target==0], 'r', 'b'), label='Class 0')\n",
        "    plt.scatter(x1[target==1], x2[target==1], marker='v', c=np.where(pred[target==1], 'r', 'b'), label='Class 1')\n",
        "    plt.legend()\n",
        "    if len(beta) >= 3 and (beta[2]!=0 or beta[1]!=0):\n",
        "        if beta[2]==0:\n",
        "            plt.vlines(-beta[0]/beta[1],x2.min(), x2.max(), ls='-.', colors='black')\n",
        "        else:\n",
        "            u = np.linspace(min(x1), max(x1), 100)\n",
        "            v = -(beta[0] + beta[1]*u) / beta[2]\n",
        "            plt.plot(u,v, ls='-.', c='black')\n",
        "    plt.xlabel('Atributo 1 - x1')\n",
        "    plt.ylabel('Atributo 2 - x2')\n",
        "    plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-MlLRxxfV3Y"
      },
      "outputs": [],
      "source": [
        "#Tu turno...\n",
        "w =[\n",
        "    0, #beta0\n",
        "    1, #beta1\n",
        "    1, #beta2\n",
        "    ]\n",
        "\n",
        "preds = model(COMPLETAR)\n",
        "plot(COMPLETAR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6Q4nLbcfV3a"
      },
      "source": [
        "Éste es el más sencillo de los métodos llamados de _función discriminante_. Estos consisten en ajustar una función escalar, cuyo valor determina la clase a la que pertenece, dependiendo de si está por encima o debajo del _umbral de decisión_.\n",
        "\n",
        "A esta función lineal, cuando se combina con un método particular para elegir los pesos $\\beta$, se le llama _modelo_. Un caso particular es el llamado _Perceptrón_ que corresponde a elegir el $\\beta$ que minimice el número de puntos mal clasificados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uy3xe1X5fV3b"
      },
      "source": [
        "## Regresor Logístico\n",
        "\n",
        "El regresor logístico es un método discriminativo, es decir que nos provee no sólo la predicción de _a que clase pertenece una muestra_, sino que responde a la pregunta de _cual es la probabilidad de que una muestra pertenezca a una clase_. Esta probabilidad podrá ser luego usada para clasificar (es decir, usando la probabilidad como función discriminante), donde se asigna cada muestra a la clase más probable (umbral = 0.5) o de otra forma a su elección.\n",
        "\n",
        "Es un _modelo lineal generalizado_, es decir que se basa en un modelo lineal cuyo resultado se pasa por una _función de vínculo_ que en este caso es la función sigmoide.\n",
        "Matemáticamente:\n",
        "$$ p = \\sigma(\\beta_0 + \\beta_1 x^{(i)}_1 + ... + + \\beta_N x^{(i)}_N) $$\n",
        "\n",
        "siendo $\\sigma $ la función sigmoide $\\sigma(z) = \\frac{1}{1 + e^{-z}}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPKkHu_ufV3c"
      },
      "outputs": [],
      "source": [
        "#Grafico la función sigmoide\n",
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "z = np.linspace(-10,10)\n",
        "plt.plot(z, sigmoid(z))\n",
        "plt.xlabel(\"z\")\n",
        "plt.ylabel(\"$\\sigma (z)$\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ur0E_DSvUevQ"
      },
      "source": [
        "**Ejercicio**\n",
        "1. Use el regresor logístico de Scikit-Learn para ajustar los datos. Utilice el parámetro `penalty = 'none'`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2VOmzsaUevQ"
      },
      "outputs": [],
      "source": [
        "# COMPLETAR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eA2c4IjQUevR"
      },
      "source": [
        "2. Calcule el vector de probabilidades predichas por el modelo ajustado sobre el dataset. Examine e interprete su resultado.\n",
        "\n",
        "*Pistas: `.predict_proba(X)`*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pHmVFYmuUevR"
      },
      "outputs": [],
      "source": [
        "# COMPLETAR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jy4gPwVAUevR"
      },
      "source": [
        "3. Obtenga los pesos del modelo lineal y utilícelos para graficar la frontera de decisión.\n",
        "\n",
        "*Pistas:*\n",
        "- Considere los atributos `.coef_` y `.intercept_` del regresor logístico.\n",
        "- La frontera de decisíon (típicamente) se obtiene cuando la sigmoide toca el umbral 0.5. Sabiendo esto:\n",
        "    * Con lápiz y papel, obtenga la fórmula para la frontera de decisión.\n",
        "    * Valerse de la función de ploteo utilizada anterioremente para graficar la frontera."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLpf-wkofV3e"
      },
      "outputs": [],
      "source": [
        "# COMPLETAR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kdN4t2liUevR"
      },
      "outputs": [],
      "source": [
        "# COMPLETAR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmo_N-wbfV3h"
      },
      "source": [
        "4. Utilice la siguiente función para graficar la frontera de decisión y los puntos de entrenamiento. Interprete."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xyGklImQfV3i"
      },
      "outputs": [],
      "source": [
        "# Función que nos ayuda a graficar\n",
        "# No hace falta que comprandan este bloque de código.\n",
        "def visualize_classifier(model, X, y, ax=None, proba = False):\n",
        "    if isinstance(X, pd.DataFrame):\n",
        "        X = X.values\n",
        "    if isinstance(y, pd.Series):\n",
        "        y = y.values\n",
        "    ax = ax or plt.gca()\n",
        "\n",
        "    colors_tab10 = plt.cm.tab10.colors\n",
        "\n",
        "    for i, y_value in enumerate(reversed(np.unique(y))):\n",
        "        ax.scatter(X[y==y_value, 0], X[y==y_value, 1], s=30,\n",
        "                   zorder=3, alpha = 0.5, color = colors_tab10[i])\n",
        "\n",
        "    ax.axis('tight')\n",
        "    ax.set_xlabel('x1')\n",
        "    ax.set_ylabel('x2')\n",
        "    # ax.axis('off')\n",
        "    xlim = ax.get_xlim()\n",
        "    ylim = ax.get_ylim()\n",
        "\n",
        "    xx, yy = np.meshgrid(np.linspace(*xlim, num=200),\n",
        "                         np.linspace(*ylim, num=200))\n",
        "\n",
        "    if proba:\n",
        "        Z = model.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:,1].reshape(xx.shape)\n",
        "    else:\n",
        "        Z = model.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
        "\n",
        "\n",
        "    # Create a color plot with the results\n",
        "    Z = -Z + 1\n",
        "    ax.pcolormesh(xx,yy,Z,cmap='bwr', vmin = 0, vmax=1, alpha = 0.2)\n",
        "\n",
        "    ax.set(xlim=xlim, ylim=ylim)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQiWd1OHfV3i"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(1,1, figsize = (7,5))\n",
        "visualize_classifier(lr, X, y, ax = axs, proba = True)\n",
        "axs.set_xlabel('Atributo 1 - x1')\n",
        "axs.set_ylabel('Atributo 2 - x2')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPhtmW-JfV3i"
      },
      "source": [
        "**Ejercicio - Para pensar e implementar:** En la regresión lineal vimos que era importante escalar los datos. ¿Y con la regresión logística?¿Cómo se interpretan los coeficientes? Implementa.\n",
        "\n",
        "#### Conjunto de datos de Pingüinos\n",
        "\n",
        "Aplica lo visto al conjunto de datos de Pingüinos. La tarea consiste en clasificar el genero de los pingüinos a partir de sus características físicas.\n",
        "\n",
        "**Ejercicio:** Selecciona dos atributos donde te parezca que las dos clases sean linealmente separables y utiliza un modelo de Regresión Logística. Comparar con los resultados obtenidos al aplicar un Árbol de Decisión. Evalúa ambos modelos usando las herramientas vistas en la guía de Evaluación. Visualiza la frontera. ¿Qué observas?\n",
        "\n",
        "**Ejercicio:**  Repite para otros pares de atributos donde no parezca haber una separación lineal. ¿Qué observas?.\n",
        "\n",
        "**Ejercicio:** Repite los ejercicios anteriores, pero usando más de dos atributos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQxnktuCfV3j"
      },
      "outputs": [],
      "source": [
        "# COMPLETAR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qNQXLQyfV3j"
      },
      "source": [
        "\n",
        "\n",
        "## 2. Curva ROC\n",
        "\n",
        "La curva ROC es un gráfico de $TPR$ en función de $FPR$ para un modelo dado. Recordemos que\n",
        "\n",
        "$TPR = \\frac{VP}{VP + FN}$\n",
        "\n",
        "$FPR = \\frac{FP}{FP + VN}$\n",
        "\n",
        "FPR es fácilmente interpretable como la proporción de instancias negativas que fueron falsamente clasificadas como positivas. De esta manera, el FPR informa efectivamente sobre el desempeño del modelo sobre la clase negativa, ya que su complemento es la tasa de aciertos sobre esa clase.\n",
        "\n",
        "De esta forma, la curva ROC representa compromisos relativos entre beneficios (verdaderos positivos) y costos (falsos positivos). Un clasificador discreto - que solamente devuelve etiquetas - está representado como un único punto en el espacio ROC. En el extremo inferior izquierdo ($FPR = 0, TPR = 0$) se ubica el clasificador que siempre predice la clase negativa; en ese caso, nunca obtiene un falso positivo, pero tampoco un verdadero positivo. En el extremo superior derecho ($FPR = 1, TPR = 1$) se encuentra el caso contrario, el que siempre predice la clase positiva. Un clasificador ideal se encuentra en la esquina superior izquierda ($FPR = 0, TPR = 1$). Un punto sobre la línea diagonal identidad ($FPR = TPR = p$) corresponde a un clasificador que asigna la clase positiva al azar con probabilidad $p$.\n",
        "\n",
        "Más interesante es el análisis ROC de clasificadores que devuelven un puntaje (score) de pertenencia a cada clase (algunos autores reservan la palabra modelo para estos clasificadores). El comportamiento por defecto es asignar la etiqueta correspondiente a la clase con mayor puntaje; sin embargo, otra opción consiste en asignar la etiqueta positiva únicamente cuando el puntaje supera cierto umbral, caso contrario asigna una etiqueta negativa. De esta forma, se obtiene una sucesión de puntos en el espacio ROC, cada uno asociado a un umbral distinto. La curva ROC así obtenida posee un conjunto de ventajas que la convierten en una herramienta sumamente interesante para evaluar el desempeño de los modelos:\n",
        "\n",
        "* La comparación de un modelo con modelos de referencia (siempre positivo, siempre negativo, aleatorio) es inmediata.\n",
        "* Permite elegir el umbral de discriminación para un modelo de acuerdo a ciertas necesidades operativas, explícitamente evaluando los compromisos entre verdaderos positivos y falsos positivos.\n",
        "* El área bajo la curva ROC (AUC-ROC) sirve como métrica de desempeño de un modelo. Esta métrica estima la probabilidad de que una instancia de la clase positiva elegida al azar tenga un puntaje más alto que una instancia negativa elegida al azar. Esta métrica toma valores entre 0 y 1, pero la cota inferior realista es 0.5, que corresponde a un modelo aleatorio.\n",
        "* La comparación entre modelos puede realizarse a través del AUC-ROC o, más en detalle, observando regiones donde un modelo supera en desempeño a otro. Otra forma es a través del uso de la Envolvente Convexa ROC (ROC convex hull) que no exploraremos en este notebook.\n",
        "* La curva ROC, así como lo son el TPR y el FPR, es invariante frente al desbalance de clases $r$ en el limite poblacional, aunque sí es posible observar algunas variaciones estadísticas en los casos muestrales a medida que $r$ varía.\n",
        "\n",
        "El análisis de curvas ROC puede ser sumamente rico e informativo, extendiéndose más allá de las características aquí mencionadas.\n",
        "\n",
        "**Para Pensar:** ¿Por qué TPR y FPR son métricas que no dependen del balance de clases?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hqu3ZcKYfV3j"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, ConfusionMatrixDisplay\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_blobs\n",
        "\n",
        "X, y = make_blobs(n_samples=1000, centers=2, cluster_std=3.5, random_state=42)\n",
        "\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y, s=50)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UBrfDerfow5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2L8Yf0Eu4R4"
      },
      "outputs": [],
      "source": [
        "# Dividir el dataset en conjunto de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf_rl = LogisticRegression(penalty=None)\n",
        "\n",
        "clf_rl.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "bA39zs2wsqVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wM94NUXKfV3j"
      },
      "outputs": [],
      "source": [
        "y_train_proba = clf_rl.predict_proba(X_train)[:,1]\n",
        "y_test_proba = clf_rl.predict_proba(X_test)[:,1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpNAnnMVfV3j"
      },
      "source": [
        "Comparemos los score predichos en cada conjunto:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eA4VK5QQfV3k"
      },
      "outputs": [],
      "source": [
        "p_1_train = y_train_proba[y_train==1]\n",
        "p_0_train = y_train_proba[y_train==0]\n",
        "\n",
        "p_1_test = y_test_proba[y_test==1]\n",
        "p_0_test =  y_test_proba[y_test==0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWXoA45PfV3k"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(1,2, figsize = (12,4))\n",
        "\n",
        "axs[0].set_title('Train')\n",
        "axs[0].hist(p_0_train, label='0', alpha=0.5, density=True, bins = np.linspace(0,1,21))\n",
        "axs[0].hist(p_1_train, label='1', alpha = 0.5, density=True, bins = np.linspace(0,1,21))\n",
        "axs[0].set_xlabel('p(1)')\n",
        "# axs[0].set_yscale('log')\n",
        "axs[0].legend()\n",
        "\n",
        "axs[1].set_title('Test')\n",
        "axs[1].hist(p_0_test, label='0', alpha = 0.5, density=True, bins = np.linspace(0,1,21))\n",
        "axs[1].hist(p_1_test, label='1', alpha = 0.5, density=True, bins = np.linspace(0,1,21))\n",
        "axs[1].set_xlabel('p(1)')\n",
        "# axs[1].axvline(0.2, ls='--', color = 'k')\n",
        "# axs[1].set_yscale('log')\n",
        "axs[1].legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCWzHxa8fV3k"
      },
      "source": [
        "### Curva ROC *a mano*\n",
        "\n",
        "Vamos a hacer una curva ROC *a mano*. Esto significa ir variando el umbral de clasificación sobre los scores predichos y calcular el TPR y FPR. ¿Cómo está relacionado con el gráfico anterior? A modo de recordatorio, la curva ROC es un gráfico de $TPR$ en función de $FPR$ para un modelo dado, donde\n",
        "\n",
        "$TPR = \\frac{VP}{VP + FN}$\n",
        "\n",
        "$FPR = \\frac{FP}{FP + VN}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MqtbEK8sfV3l"
      },
      "outputs": [],
      "source": [
        "threholds = np.linspace(-0.01, 1.01, 103)\n",
        "TPR = []\n",
        "FPR = []\n",
        "precision = []\n",
        "positives = y_test.sum()\n",
        "negatives = COMPLETAR\n",
        "\n",
        "\n",
        "for threhold in threholds:\n",
        "    predictions = COMPLETAR.astype(int)\n",
        "    TP = ((y_test == 1) & (predictions == 1)).sum()\n",
        "    FP = COMPLETAR\n",
        "    FN = COMPLETAR\n",
        "    VN = COMPLETAR\n",
        "\n",
        "    TPR.append(COMPLETAR)\n",
        "    FPR.append(COMPLETAR)\n",
        "    precision.append(COMPLETAR)\n",
        "\n",
        "TPR = np.array(TPR)\n",
        "FPR = np.array(FPR)\n",
        "precision = np.array(precision)\n",
        "recall = TPR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHbQydspfV3l"
      },
      "source": [
        "Graficamos junto con la curva obtenida por Scikit-Learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qapY8mZ2fV3l"
      },
      "outputs": [],
      "source": [
        "plt.scatter(FPR, TPR, label = 'Curva ROC a mano', s = 16, color = 'green', alpha = 0.75)\n",
        "\n",
        "### CURVA DE SCIKIT LEARN\n",
        "fpr, tpr, _ = roc_curve(y_test, y_test_proba)\n",
        "\n",
        "plt.plot(fpr, tpr, ls = '--', label = 'Curva ROC Scikit-Learn')\n",
        "plt.plot(FPR_random, TPR_random, ls = '--',color = 'k', label = 'Modelo Aleatorio')\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "plt.xlabel('FPR')\n",
        "plt.ylabel('TPR')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWotaXetfV3m"
      },
      "source": [
        "**Ejercicio:** calcula el área bajo la curva ROC. Las funciones  `auc` y `roc_auc_score` de Scikit-Learn pueden ser de utilidad."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EiSj7v1yfV3m"
      },
      "outputs": [],
      "source": [
        "# COMPLETAR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFrjYUYTfV3m"
      },
      "source": [
        "**Ejercicio:** Nuevamente, aplica lo visto al conjunto de datos de Pingüinos, en la tarea para clasificar el genero de los pingüinos a partir de sus características físicas. Investiga cómo usar la métrica AUC-ROC junto con validación cruzada en Scikit-Learn. Calcula el AUC-ROC para un modelo de Regresión Logística y observa qué ocurre a medida que aumentamos el número de atributos utilizados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BI-nP2oXfV3m"
      },
      "source": [
        "### Otras métricas\n",
        "\n",
        "Podemos ver cómo varían algunas métricas a medida que variamos el umbral"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vWhTlkcjfV3m"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(1,2, figsize = (12,4))\n",
        "axs[0].plot(threholds, recall, label = 'Exhaustividad/TPR')\n",
        "axs[0].plot(threholds, FPR, label = 'FPR')\n",
        "axs[0].plot(threholds, precision, label = 'Precisión')\n",
        "\n",
        "\n",
        "axs[0].legend()\n",
        "axs[0].set_xlabel('Umbral')\n",
        "\n",
        "axs[1].plot(threholds, recall, label = 'Exhaustividad/TPR')\n",
        "axs[1].plot(threholds, FPR, label = 'FPR')\n",
        "axs[1].plot(threholds, 2*(precision*recall)/(precision+recall), label = 'F-Score')\n",
        "\n",
        "axs[1].legend()\n",
        "axs[1].set_xlabel('Umbral')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXVdYGdJfV3n"
      },
      "source": [
        "La curva Precisión/Exhaustividad es otra curva que se pueden encontrar. Hay que tener cierta precausión con esta curva, porque depende del balance de clases a través de la precisión. Interpreta cada extremo de la curva."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3nzf9o41fV3s"
      },
      "outputs": [],
      "source": [
        "plt.plot(recall, precision)\n",
        "plt.xlabel('Exhaustividad/TPR')\n",
        "plt.ylabel('Precisión')\n",
        "plt.grid()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "964b008cb5ef2a660594f048d86c2599bd9046de6f673691130e1855aa2f0225"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}