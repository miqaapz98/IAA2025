{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIZ0eNR1uO45"
      },
      "source": [
        "# Introducción al Aprendizaje Automático\n",
        "\n",
        "## Ensambles\n",
        "\n",
        "**Ejercicio:** Importar de Scikit-Learn las clases *BaggingClassifier*, *RandomForestClassifier* y *AdaBoostClassifier* y estudiar sus hiperparámetros, métodos y atributos. Leer bien la documentación.\n",
        "\n",
        "**Ejercicio:** Seleccionar algún problema de clasificación o regresión en los que hayan trabajado (puede ser sobre el conjunto de datos de pingüinos, el conjunto de datos del TP o algún otro) y aplicar los tres métodos de ensamble mencionados. Comparar los resultados obtenidos con algún modelo sencillo previamente utilizado. ¿Cómo son los desempeños obtenidos en train y test?. Si es posible, visualizar los resultados obtenidos. Para el caso particular de *Random Forest*:\n",
        "1. ¿Cuál es su `oob_score_`? ¿Y que son `feature_importances_`?\n",
        "1. ¿Qué hay en el atributo `estimators_`? Elegir uno de los `estimators_` y evaluar su desempeño sobre train y test.\n",
        "\n",
        "**Nota:** si no sabés cuál conjunto de datos utilizar, recomendamos éste: https://www.kaggle.com/jsphyg/weather-dataset-rattle-package\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MTanDeg4xyXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ejercicio - XGBoost:** Entrenar un modelo con `XGBoost` sobre el mismo problema. Estudiar sus [hiperparámetros](https://xgboosting.com/most-important-xgboost-hyperparameters-to-tune/)"
      ],
      "metadata": {
        "id": "nNykZcMix0du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier, XGBRegressor\n",
        "# !pip install xgboost # si falla"
      ],
      "metadata": {
        "id": "sQB6zWZ-x0_N"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ejercicio:** Dar una explicación general de *Bagging* y *Random Forest*. ¿Cuál es su principal diferencia?\n",
        "\n",
        "**Ejercicio:** Investigar cómo se calcula la importancia de los features en un modelo de Random Forest de Scikit-Learn.\n",
        "\n",
        "**Ejercicio:** Investigar cómo funciona la estimación de error “out-of-bag” en Random Forest.\n",
        "\n",
        "**Ejercicio:** Sea un clasificador binario de tipo Random Forest entrenado sobre un conjunto de datos de entrenamiento. Al evaluar 10 instancias el clasificador devuelve las siguientes probabilidades de pertenencia a la clase positiva: [0.75, 0.75, 0.25, 0.75, 1.0, 0.0, 0.50, 0.75, 1.0]. Determinar la cantidad de árboles utilizados en el ensamble. Justificar o explicitar las hipótesis utilizadas.\n",
        "\n",
        "**Ejercicio:** Dar una explicación general de *AdaBoost* siguiendo la explicación presentada en el libro *The Data Science Design Manual* de Steven S. Skiena. ¿Qué es un \"weak-learner\"? ¿Cuál es la diferencia con *Gradient Boosting*?\n",
        "\n",
        "**Ejercicio:** Investigar qué es *Stacking*."
      ],
      "metadata": {
        "id": "rC8biz5yxtkC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SE-_B7iKxsov"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}